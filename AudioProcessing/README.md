# Audio Processing

Description: This folder doesn't have any models in it. It attempts to look at different ways to load and process audio data across different libraries such as PyTorch, Tensorflow, Librosa, and Scipy.


### Notes

 * Reading (wav) files
     * When reading a (wav) audio file, scipy loads data to a numpy array of dtype int16. Converting to float32 does not result in the numpy array matching the other numpy arrays from the other libraries (their defualt dtypes are float32). Converting the other numpy arrays to int16 would result in data loss (which isnt great).
     * In the Nvidia [Tacotron 2 repo](https://github.com/NVIDIA/tacotron2) (the baseline), files are read with the scipy module and converted to float32 (see `load_wav_to_torch()` in `utils.py` of the repo). If we are to compare to that baseline, the numpy arrays generated by the other libraries will have to be convert to int16 before converting them back to float32 to have a realistic comparison.
         * Currently, even converting everything to int16 numpy arrays does not result in any matches the one generated by scipy.
 * Converting audio to Mel Spectrograms
     * For Tacotron2 STFT conversion, the following files are used to process the audio:
         * `layers.py`: Contains the PyTorch TacotronSTFT module.
         * `audio_processing.py`: Contains functions for dynamic range compression & decompression.
         * `stft.py`: Contains the PyTorch STFT module used in TacotronSTFT.
     * Within `process_audio.py`:
         * The `get_mel_tfio()` function relies on Tensorflow IO and isnt really tested.
         * The `get_spectrogram_tf()` function does not output an array of the expected shape. This is most likely because it extracts the magnitude of the spectrogram signal (thus making it a linear spectrogram and not mel spectrogram). The linear to mel weight matrix is multiplied with it to get the mel spectrogram (as seen in `get_mel_spec_tf()`).
         * The `get_spectrogram_tf()` function was pulled from the Keras [ASR with CTC example](https://keras.io/examples/audio/ctc_asr/#preprocessing) while `get_mel_spec_tf()` was pulled from the Keras [Mel-GAN Spectrogram Inversion Feature Matching example](https://keras.io/examples/audio/melgan_spectrogram_inversion/).
     * The `get_mel_spec_tf()` function outputs a shape that is different from `get_mel_librosa()` and `TacotronSTFT`, but that is because it is in the form `[n_mel_channels, melspec_length]` while the other two are in `[melspec_length, n_mel_chanhels]`. It is also important to note that the `melspec_length` from `get_mel_spec_tf()` is slightly shorter than from the other two functions (usually by 4 timesteps) while the `melspec_length` from `get_mel_librosa()` and `TacotronSTFT` match perfectly.