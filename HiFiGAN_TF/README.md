# README

Description: HiFi-GAN is a GAN based vocoder used with neural text to speech models.

### Notes:

 * Tensors in Pytorch would be shaped (batch_size, channels, height, width) while tensors in Tensorflow are shaped (batch_size, height, width, channels). The channels dim/axis is what is operated on by each framework's respective layers so there is a need to transpose the tensors in this tensorflow implementation (I cannot vouch for its correctness but I can say that the model is able to build & run).


### Notes

 * Changes from the [Original Repo](https://github.com/jik876/hifi-gan):
     * The training and validation files are specified via the arguments passed into `train.py`. I swapped that out for the setup that I have in GradTTS & FastPitch, where the files are in a folder called `filelists/` and read from there.
     * `mel_dataset.py` is an attempt to emulate the original data loading function from PyTorch. Given that the original uses `scipy.io.wavfile.read()` to read in the audio data, there will be some slight differences in the data when compared to using tensorflow to read in the audio (as shown in the `AudioProcessing/` folder). Thus, there isn't really a reason to use it over the `data.py` module that's been create and used across the other audio models.
 * Tried to add a `build()` call for the models (generator and discriminators) but found it quite cumbersome. For that reason, I've also created methods to initialize the models via Tensorflow's functional API. I dont like it compared to sub-classing `tf.keras.Model` but the models can be built immediately after initialization.
     * Additionally, I found an issue when trying to initialize the mpd discriminator model, there seemed to be an issue with the shape of the tensor (because the DiscriminatorP layer breaks down the inputs into its base dimensions). Need to investigate further by finishing data loading & comparing it to the original repo (particularly the audio or y input to the discriminator models).
 * In `data.py`, the `Data` class is the main data loader for the HiFi GAN model. The old data loader (`DataOld` class) was based on the data loaders for the text to speech models (GradTTS, FastPitch, Tacotron2), but was insufficient as it only returned the mel spectrograms and the mel spectrogram lengths for each sample. The new data loader is returning the input mel spectrogram, the audio, file name, and the mel loss mel spectrogram. There are also several caveats with the new data loader as well.
     * `mel_loss` is the mel spectrograms generated from tacotron 2 as a part of teacher-forcing for fine-tuning only. In training, this would probably be the same as `fmax`.
     * `fmax_mel_loss` is the `fmax` for preprocessing the mel loss mel spectrogram.
     * The new data loader is much faster than the old data loader despite not having the ability to cache processed data to (.npy) files.
         * The old data loader required two passes through the data. One to acquire the max length of the mel spectrograms and the second pass was to pad the data to that length accordingly. On a cold start, this required 10 minutes for each pass, leading to a total of 20 minutes to process the training data. The processed mel spectrograms were saved to (.npy) files as a sort of caching mechanism to reduce the amount of time spent in processing the audio. This cut down warm start times to 2.5 minutes for the initial pass and 7 minutes for the second pass, resulting in 10 minutes for total data processing (reduced time by 50%).
         * The new data load requires only one pass through the data, but cannot take advantage of caching with files due to randomness in the workflow. In addition, the audio is sub-sampled or padded accordingly to fit a set length (`segment_size`) meaning that there is no need to dedicate an entire pass through the data to find the max lengths. This also means that not all the audio data is being processed if it is larger than that `segment_size`. These attributes greatly reduced the time needed to load the data to a `tf.data.Dataset` to 7 minutes every time, regardless of warm start or cold start.
     * `base_mels_path` is another variable used for the folder containing the mel spectrograms generated by tacotron 2. It is only a concern for fine-tuning HiFi GAN and not really for training. 


### TODO List (for V1 release)

 1. Finish Model architecture
     * Iron out the padding for the conv layers
     * Go back and add weight initializer for respective layers
     * Implement initialization, training loop, model saving/loading, and compiling in `gan.py`. Alternatively, implement everything in `train.py`
 2. ~~Implement data loading~~
 3. Implement everything required for training (this can be done either in `gan.py` or `train.py`)
     * Model initialization
     * Model compilation
         * Model loss
         * Model optimizer
     * Training loop
     * Model saving/loading (includes resume saving from epoch)