# inference.py


from argparse import ArgumentParser
import os
import numpy as np
import tensorflow as tf
from params import params
from model import DiffWave


def predict(spectrogram=None, model_dir=None, params=None, 
		fast_sampling=False):
	if model_dir is None:
		raise ValueError(f"model_dir must be specified")

	# Load model from model_dir.
	model = tf.keras.models.load_model(model_dir)

	# Initialize noise schedule.
	training_noise_schedule = np.array(model.params.noise_schedule)
	inference_noise_schedule = np.array(
		model.params.inference_noise_schedule
	) if fast_sampling else training_noise_schedule

	# Change in notation from the DiffWave paper for fast sampling.
	# DiffWave paper -> Implementation below
	# --------------------------------------
	# alpha -> talpha
	# beta -> training_noise_schedule
	# gamma -> alpha
	# eta -> beta
	talpha = 1 - training_noise_schedule
	talpha_cum = np.cumprod(talpha)

	beta = inference_noise_schedule
	alpha = 1 - beta
	alpha_cum = np.cumprod(alpha)

	T = []
	for s in range(len(inference_noise_schedule)):
		for t in range(len(training_noise_schedule) - 1):
			if talpha_cum[t + 1] <= alpha_cum[s] <= talpha_cum[t]:
				twiddle = (talpha_cum[t] ** 0.5 - alpha_cum[s] ** 0.5) / (talpha_cum[t] ** 0.5 - talpha_cum[t + 1] ** 0.5)
				T.append(t + twiddle)
				break
	T = np.array(T, dtype=np.float32)
	T = tf.convert_to_tensor(T, dtype=tf.float32)

	if not model.params.unconditional:
		if len(spectrogram.shape) == 2:# Expand rank 2 tensors by adding a batch dimension.
			# spectrogram = spectrogram.unsqueeze(0) # Original
			spectrogram = tf.expand_dims(spectrogram, 0)
		# audio = torch.randn(spectrogram.shape[0], model.params.hop_samples * spectrogram.shape[-1]) # Original
		audio = tf.random.normal(
			(
				spectrogram.shape[0],							# batch_size
				model.params.hop_length * spectrogram.shape[1],	# audio length
			)
		)
	else:
		# audio = torch.randn(1, params.audio_len) # Original
		audio = tf.random.normal((1, params.audio_len))
		# noise_scale = torch.from_numpy(alpha_cum**0.5).float().unsqueeze(1) # Original
		noise_scale = tf.expand_dims(
			tf.convert_to_tensor(alpha_cum ** 0.5, dtype=tf.float32), 1
		)

	for n in range(len(alpha) - 1, -1, -1):
		c1 = 1 / alpha[n] ** 0.5
		c2 = beta[n] / (1 - alpha_cum[n]) ** 0.5
		audio = c1 * (audio - c2 * model(audio, torch.tensor([T[n]]), spectrogram).squeeze(1))
		if n > 0:
			noise = torch.randn_like(audio)
			sigma = ((1.0 - alpha_cum[n-1]) / (1.0 - alpha_cum[n]) * beta[n])**0.5
			audio += sigma * noise
			audio = torch.clamp(audio, -1.0, 1.0)

	return audio, model.params.sample_rate


def main():
	parser = ArgumentParser(description='runs inference on a spectrogram file generated by diffwave.preprocess')
	parser.add_argument('model_dir',
		help='directory containing a trained model (or full path to weights.pt file)')
	parser.add_argument('--spectrogram_path', '-s',
		help='path to a spectrogram file generated by diffwave.preprocess')
	parser.add_argument('--output', '-o', default='output.wav',
		help='output file name')
	parser.add_argument('--fast', '-f', action='store_true',
		help='fast sampling procedure')
	args = parser.parse_args()

	if args.spectrogram_path:
		spectrogram = tf.convert_to_tensor(
			np.load(args.spectrogram_path)
		)
	else:
		spectrogram = None

	audio, sr = predict(
		spectrogram, args.model_dir, fast_sampling=args.fast,
		params=params
	)
	tf.io.write_file(args.output, tf.audio.encode_wav(audio, sr))

	# Exit the program.
	exit(0)


if __name__ == '__main__':
	main()