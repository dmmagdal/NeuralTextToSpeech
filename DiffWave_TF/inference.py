# inference.py


from argparse import ArgumentParser
import os
import numpy as np
import tensorflow as tf
from common.audio_processing_tf import STFT
from data import load_wav_to_tensorflow
from params import params
from model import DiffWave


# @tf.function
def predict(spectrogram=None, model_dir=None, params=None, 
		fast_sampling=False):
	if model_dir is None:
		raise ValueError(f"model_dir must be specified")

	# Load model from model_dir.
	model = tf.keras.models.load_model(model_dir)

	# Initialize noise schedule.
	training_noise_schedule = np.array(params.noise_schedule)
	inference_noise_schedule = np.array(
		params.inference_noise_schedule
	) if fast_sampling else training_noise_schedule

	# Change in notation from the DiffWave paper for fast sampling.
	# DiffWave paper -> Implementation below
	# --------------------------------------
	# alpha -> talpha
	# beta -> training_noise_schedule
	# gamma -> alpha
	# eta -> beta
	talpha = 1 - training_noise_schedule
	talpha_cum = np.cumprod(talpha)

	beta = inference_noise_schedule
	alpha = 1 - beta
	alpha_cum = np.cumprod(alpha)

	T = []
	for s in range(len(inference_noise_schedule)):
		for t in range(len(training_noise_schedule) - 1):
			if talpha_cum[t + 1] <= alpha_cum[s] <= talpha_cum[t]:
				twiddle = (talpha_cum[t] ** 0.5 - alpha_cum[s] ** 0.5) / (talpha_cum[t] ** 0.5 - talpha_cum[t + 1] ** 0.5)
				T.append(t + twiddle)
				break
	T = np.array(T, dtype=np.float32)
	T = tf.convert_to_tensor(T, dtype=tf.float32)

	if not params.unconditional:
		if len(spectrogram.shape) == 2:# Expand rank 2 tensors by adding a batch dimension.
			# spectrogram = spectrogram.unsqueeze(0) # Original
			spectrogram = tf.expand_dims(spectrogram, 0)
		# audio = torch.randn(spectrogram.shape[0], model.params.hop_samples * spectrogram.shape[-1]) # Original
		audio = tf.random.normal(
			(
				spectrogram.shape[0],							# batch_size
				params.hop_length * spectrogram.shape[1],		# audio length
			)
		)
	else:
		# audio = torch.randn(1, params.audio_len) # Original
		audio = tf.random.normal((1, params.audio_len))
		# noise_scale = torch.from_numpy(alpha_cum**0.5).float().unsqueeze(1) # Original
		noise_scale = tf.expand_dims(
			tf.convert_to_tensor(alpha_cum ** 0.5, dtype=tf.float32), 1
		)

	print(spectrogram.shape)
	print(audio.shape)
	exit()

	for n in range(len(alpha) - 1, -1, -1):
		c1 = 1 / alpha[n] ** 0.5
		c2 = beta[n] / (1 - alpha_cum[n]) ** 0.5
		# audio = c1 * (audio - c2 * model(audio, torch.tensor([T[n]]), spectrogram).squeeze(1))
		audio = c1 * tf.squeeze(
			audio - c2 * model([audio, tf.convert_to_tensor([T[n]]), spectrogram]),
			-1
		)
		if n > 0:
			# noise = torch.randn_like(audio)
			noise = tf.random.uniform((audio.shape))
			sigma = ((1.0 - alpha_cum[n - 1]) / (1.0 - alpha_cum[n]) * beta[n]) ** 0.5
			audio += sigma * noise
		# audio = torch.clamp(audio, -1.0, 1.0)
		audio = tf.clip_by_value(audio, -1.0, 1.0)

	return audio, params.sample_rate


# @tf.function
def main():
	parser = ArgumentParser(description='runs inference on a spectrogram file generated by diffwave.preprocess')
	# parser.add_argument('model_dir',
	# 	help='directory containing a trained model (or full path to weights.pt file)')
	parser.add_argument('--spectrogram_path', '-s',
		help='path to a spectrogram file generated by diffwave.preprocess')
	parser.add_argument('--output', '-o', default='output.wav',
		help='output file name')
	parser.add_argument('--fast', '-f', action='store_true',
		help='fast sampling procedure')
	args = parser.parse_args()

	if args.spectrogram_path:
		spectrogram = tf.convert_to_tensor(
			np.load(args.spectrogram_path)
		)
	else:
		# spectrogram = None
		max_wav_value = 32768.0
		stft = STFT(
			filter_length=params.n_fft, 
			frame_step=params.hop_length,
			frame_length=params.win_length, 
			sampling_rate=params.sample_rate,
			mel_fmin=params.f_min, mel_fmax=params.f_max
		)
		filename = './LJSpeech-1.1/wavs/LJ001-0001.wav'

		audio, sampling_rate = load_wav_to_tensorflow(filename)
		audio_norm = audio / max_wav_value
		audio_norm = tf.expand_dims(audio_norm, 0)
		spectrogram = stft.mel_spectrogram(audio_norm)

	model_dir = "./diff_wave"

	audio, sr = predict(
		spectrogram, model_dir, fast_sampling=args.fast,
		params=params
	)
	tf.io.write_file(args.output, tf.audio.encode_wav(audio, sr))

	# Exit the program.
	exit(0)


if __name__ == '__main__':
	with tf.device('/cpu:0'):
		main()